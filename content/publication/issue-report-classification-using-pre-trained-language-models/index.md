---
abstract: This paper describes our participation in the tool competition
  organized in the scope of the 1st International Workshop on Natural
  Language-based Software Engineering. We propose a supervised approach relying
  on fine-tuned BERT-based language models for the automatic classification of
  GitHub issues. We experimented with different pre-trained models, achieving
  the best performance with fine-tuned RoBERTa (F1 = .8591).
slides: ""
url_pdf: ""
publication_types:
  - "1"
authors:
  - Giuseppe Colavito
  - Filippo Lanubile
  - Nicole Novielli
author_notes: []
publication: Proceedings of the 1st International Workshop on Natural
  Language-based Software Engineering
summary: ""
url_dataset: ""
url_project: ""
publication_short: NLBSE'22
url_source: ""
url_video: ""
title: Issue Report Classification Using Pre-Trained Language Models
doi: https://doi.org/10.1145/3528588.3528659
featured: false
tags: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: true
date: 2022-05-21T16:39:10.932Z
url_slides: ""
publishDate: 2017-01-01T00:00:00.000Z
url_poster: ""
url_code: ""
---
