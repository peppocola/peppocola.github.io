@inproceedings{10.1145/3528588.3528659,
author = {Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole},
title = {Issue Report Classification Using Pre-Trained Language Models},
year = {2023},
isbn = {9781450393430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528588.3528659},
doi = {10.1145/3528588.3528659},
abstract = {This paper describes our participation in the tool competition organized in the scope of the 1st International Workshop on Natural Language-based Software Engineering. We propose a supervised approach relying on fine-tuned BERT-based language models for the automatic classification of GitHub issues. We experimented with different pre-trained models, achieving the best performance with fine-tuned RoBERTa (F1 = .8591).},
booktitle = {Proceedings of the 1st International Workshop on Natural Language-Based Software Engineering},
pages = {29â€“32},
numpages = {4},
keywords = {issue classification, BERT, labeling unstructured data, deep learning, software maintenance and evolution},
location = {Pittsburgh, Pennsylvania},
series = {NLBSE '22}
}
